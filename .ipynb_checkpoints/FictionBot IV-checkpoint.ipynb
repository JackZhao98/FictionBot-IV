{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fiction Bot IV\n",
    "### A notebook based automated fiction scraper + EPub generator\n",
    "This notebook is able to scrape and download all chapters from a provided internet novel url (biquge.com.cn), then auto generate a well-formatted ePub ebook, with **Table Of Contents** of course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"xbiquge.so\"\n",
    "book_url = \"https://www.xbiquge.so/book/53005/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "book_title = soup.h1.text\n",
    "author = soup.find(\"meta\", attrs={\"property\":\"og:novel:author\"})['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Folder Structure for EPub\n",
    "These two folders are necessary under the root directory\n",
    "- META-INF\n",
    "- OPS\n",
    "\n",
    "Plus a file:\n",
    "- mimetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(f\"./{book_title}\")\n",
    "except:\n",
    "    print(f\"Folder exists: ./{book_title}\")\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(f\"./{book_title}/META-INF\")\n",
    "    os.mkdir(f\"./{book_title}/OPS\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write `application/epub+zip` to the mimetype file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./{book_title}/mimetype\", \"w\") as tmp:\n",
    "    tmp.write(\"application/epub+zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `container.xml` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./{book_title}/META-INF/container.xml\", \"w\", encoding=\"utf-8\") as tmp:\n",
    "    tmp.write('''<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n",
    "<container version=\"1.0\" xmlns=\"urn:oasis:names:tc:opendocument:xmlns:container\">\n",
    "  <rootfiles>\\n    <rootfile full-path=\"OPS/content.opf\" media-type=\"application/oebps-package+xml\"/>\\n  </rootfiles>\n",
    "</container>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "opfcontent = '''<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n",
    "<package version=\"2.0\" unique-identifier=\"PrimaryID\" xmlns=\"http://www.idpf.org/2007/opf\">\n",
    "<metadata xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:opf=\"http://www.idpf.org/2007/opf\">\n",
    "%(metadata)s\n",
    "<meta name=\"cover\" content=\"cover\"/>\n",
    "</metadata>\n",
    "<manifest>\n",
    "%(manifest)s\n",
    "<item id=\"ncx\" href=\"content.ncx\" media-type=\"application/x-dtbncx+xml\"/>\n",
    "<item id=\"cover\" href=\"cover.jpg\" media-type=\"image/jpeg\"/>\n",
    "</manifest>\n",
    "<spine toc=\"ncx\">\n",
    "%(ncx)s\n",
    "</spine>\n",
    "</package>\n",
    "'''\n",
    "dc = '<dc:%(tag)s>%(value)s</dc:%(tag)s>'\n",
    "item = \"<item id='%(id)s' href='%(url)s' media-type='application/xhtml+xml'/>\"\n",
    "itemref = \"<itemref idref='%(id)s'/>\"\n",
    "metadata = '\\n'.join([\n",
    "    dc % {'tag': 'title', 'value': book_title},\n",
    "    dc % {'tag': 'creator', 'value': author},\n",
    "    dc % {'tag': 'decription', 'value': \"本文档由Fiction Bot IV自动生成\"},\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncxcontent = '''<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
    "<!DOCTYPE ncx PUBLIC \"-//NISO//DTD ncx 2005-1//EN\" \"http://www.daisy.org/z3986/2005/ncx-2005-1.dtd\">\n",
    "<ncx version=\"2005-1\" xmlns=\"http://www.daisy.org/z3986/2005/ncx/\">\n",
    "<head>\n",
    "  <meta name=\"dtb:uid\" content=\" \"/>\n",
    "  <meta name=\"dtb:depth\" content=\"-1\"/>\n",
    "  <meta name=\"dtb:totalPageCount\" content=\"0\"/>\n",
    "  <meta name=\"dtb:maxPageNumber\" content=\"0\"/>\n",
    "</head>\n",
    " <docTitle><text>%(title)s</text></docTitle>\n",
    " <docAuthor><text>%(creator)s</text></docAuthor>\n",
    "<navMap>\n",
    "%(navpoints)s\n",
    "</navMap>\n",
    "</ncx>\n",
    "'''\n",
    "navpoint = '''<navPoint id='%s' class='level1' playOrder='%d'>\n",
    "<navLabel> <text>%s</text> </navLabel>\n",
    "<content src='%s'/></navPoint>'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch all HTML tags of the menu entries, store in `menu_raw`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_raw = soup.find_all('dd')\n",
    "menu_raw = menu_raw[12:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then parse href and chapter titiles from each HTML tag, store the information in `menu_info`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MenuInfo:\n",
    "    \n",
    "    \n",
    "    def __init__(self, url, chapter_title):\n",
    "        self.url = url\n",
    "        self.chapter_title = chapter_title\n",
    "        self.id = None\n",
    "        self.epub_link = None\n",
    "    \n",
    "    def get_title(self):\n",
    "        return self.chapter_title\n",
    "    \n",
    "    def get_url(self):\n",
    "        return self.get_url\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.id}: {self.chapter_title} - {self.url} - {self.epub_link}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None: 新书《终末的绅士》已发布 - 39728608.html - None\n",
      "None: 新书《终末的绅士》及简介 - 39714241.html - None\n",
      "None: 新书预告Part.2 - 39503263.html - None\n",
      "None: 新书预告Part.1 - 39396290.html - None\n",
      "None: 完本感言 - 39394738.html - None\n",
      "None: 第二千一百六十七章 我的细胞监狱（大结局） - 39391185.html - None\n",
      "None: 第二千一百六十六章 命运合同与混沌之道 - 39375344.html - None\n",
      "None: 第二千一百六十五章 线与道路 - 39375089.html - None\n",
      "None: 第二千一百六十四章 工作交接 - 39374077.html - None\n",
      "None: 第二千一百六十三章 本质 - 39373711.html - None\n"
     ]
    }
   ],
   "source": [
    "menu_info = []\n",
    "for index, data in enumerate(menu_raw, 1):\n",
    "    try:\n",
    "        m = MenuInfo(url = data.a['href'], chapter_title = data.text)\n",
    "        menu_info.append(m)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# menu_preprocessing.sort(key=lambda x: x.url)\n",
    "for i in range(0, 10):\n",
    "    print(str(menu_info[-1-i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 第一章 神秘的监狱 - 35935698.html - chapter_1.html\n",
      "2: 第二章 韩东的发现 - 35935700.html - chapter_2.html\n",
      "3: 第三章 从头开始 - 35935701.html - chapter_3.html\n",
      "4: 第四章 上吊的青年 - 35935702.html - chapter_4.html\n",
      "5: 第五章 便携式监狱 - 35935703.html - chapter_5.html\n",
      "6: 第六章 祭典广场 - 35935704.html - chapter_6.html\n",
      "7: 第七章 命运空间 - 35935705.html - chapter_7.html\n",
      "8: 第八章 六人小队 - 35935706.html - chapter_8.html\n",
      "9: 第九章 王婆 - 35935707.html - chapter_9.html\n",
      "10: 第十章 噩梦 - 35935708.html - chapter_10.html\n"
     ]
    }
   ],
   "source": [
    "for c, d in enumerate(menu_info, 1):\n",
    "    try:\n",
    "        d.id = c\n",
    "        d.epub_link = f'chapter_{c}.html'\n",
    "    except:\n",
    "        print(d)\n",
    "    \n",
    "for i in range(0, 10):\n",
    "    print(str(menu_info[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#     'id': c, \n",
    "#     'link': f'chapter_{c}.html', \n",
    "#     'url':d.a['href'], \n",
    "#     'chapter':d.text\n",
    "# }\n",
    "\n",
    "manifest = []\n",
    "ncx = []\n",
    "navpoints = []\n",
    "for m in menu_info:\n",
    "    manifest.append(item % {'id': m.epub_link, 'url':m.epub_link})\n",
    "    ncx.append(itemref % {'id': m.epub_link})\n",
    "    navpoints.append(navpoint % (m.epub_link, m.id, m.chapter_title, m.epub_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = '\\n'.join(manifest)\n",
    "ncx = '\\n'.join(ncx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./{book_title}/OPS/content.opf', 'w', encoding=\"utf-8\") as tmp:\n",
    "    tmp.write(opfcontent % {\n",
    "        'metadata': metadata,\n",
    "        'manifest': manifest,\n",
    "        'ncx': ncx,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./{book_title}/OPS/content.ncx', 'w', encoding=\"utf-8\") as tmp:\n",
    "    tmp.write(ncxcontent % {\n",
    "        'title': book_title,\n",
    "        'creator': author,\n",
    "        'navpoints': '\\n'.join(navpoints)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\jackz\\\\Developer\\\\FictionBot-IV'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_img = soup.find(\"img\")\n",
    "if cover_img:\n",
    "    cover_img = cover_img['src']\n",
    "    img = requests.get(cover_img, stream=True)\n",
    "    if img.status_code == 200:\n",
    "        with open(f\"./{book_title}/OPS/cover.jpg\", \"wb\") as f:\n",
    "            shutil.copyfileobj(img.raw, f)\n",
    "    del img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''<html xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"zh-CN\">\n",
    "<head>\n",
    "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"css/main.css\"/>\n",
    "<title>%(title)s</title>\n",
    "</head>\n",
    "<body> c\n",
    "<h2>%(title)s</h2>\n",
    "<div>\n",
    "%(content)s\n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35935698.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<div id=\"content\" name=\"content\">笔趣阁 www.xbiquge.so，最快更新我的细胞监狱 ！<br/><br/>    污水横流、菌斑肆掠。<br><br>     某一废弃的监狱深处……<br/><br/>     啪！<br/><br/>     一团由质膜包裹的细胞团，竟从某具尸体的表面分离了出来。<br/><br/>     细胞团体仅有人类食指大小，宏观外表就像一团白色鼻涕。<br/><br/>     这一细胞团似乎具备着独立的思维与行动能力。<br/><br/>     但由于神经系统的不完善性，并无五感。<br/><br/>     不过，在细胞团与外物接触时，能通过‘细胞间信号传递’的特别手段，获取物质的基础信息。<br/><br/>     分离出来的细胞没有过久的停留，开始移动了。<br/><br/>     转录与翻译。<br/><br/>     肌动蛋白产生。<br/><br/>     这团手指头大小的细胞群体开始进行极为缓慢的‘迁移运动’，大约与蜗牛的移动速度相当。<br/><br/>     “不行……不够完美，也不是我想要的。”<br/><br/>     细胞团似乎主动舍弃了这具看似完整且强壮的肉体，继续在监狱里展开搜寻……<br/><br/>     若当前能有一束火把提供照明。<br/><br/>     你会发现这一处巨型牢房中，由细胞团所舍弃的肉体达到上百具。<br/><br/>     …………<br/><br/>     细胞团并非自主形成。<br/><br/>     它有着自己的名字-韩东。<br/><br/>     华侨，意大利佛罗伦萨大学生命科学院的副教授，在成为这团细胞凝聚体前，他刚好31岁。<br/><br/>     于2018年7月21日，因肺癌死在佛罗伦萨中心医院的病床上。<br/><br/>     病房里摆满着鲜花，然而这些鲜花却来源于他的学生，而非家人。<br/><br/>     在死亡的一刻，病痛折磨消散一空，韩东反而感觉释然。<br/><br/>     没有升入天堂或是堕入地狱，也没有喝下孟婆汤、走上来奈何桥、经历所谓的轮回转世。<br/><br/>     迎接他的只有无尽黑暗而已。<br/><br/>     然而，他的意识却在这一过程中始终存在。<br/><br/>     “我到底死没死？！人死后，大脑会继续保持活性五分钟……但我这已经死了一小时了吧？”<br/><br/>     韩东的‘时间感’极强，意识清醒的他，很清楚自己‘死亡’了多长时间。<br/><br/>     韩东慢慢试着去感知‘身体’，谁知，竟在意识中出现了细胞团的形象。<br/><br/>     只有两件事情能做到。<br/><br/>     第一、能通过胞间信号传递来感应所接触物品的详细信息。<br/><br/>     第二、通过生成肌动蛋白而产生运动能力。<br/><br/>     也就在韩东第一次在胞内合成肌动蛋白，进行相关活动时，一阵系统的提示声回荡在它的脑海中。<br/><br/>     『请在监狱内挑选‘合适’的肉体，当前最大负重值为【100】。<br/><br/>     若对所挑选的肉体不太满意，可将肉体送往处理间，进行胞体分离。<br/><br/>     非细胞形态下，不可搬动或转移其它的囚犯肉体。』<br/><br/>     提示结束。<br/><br/>     在韩东的意识层面又生成了一张监狱的平面图。<br/><br/>     单层结构<br/><br/>     总计二百零四间牢房。<br/><br/>     平面图还通过光点与注释，标注了每一牢房里对应的囚犯，并注释着‘已死亡’三个字。<br/><br/>     除此之外，监狱的中间区域显示着一处红色标记的房间，名为【管理室】并处于上锁状态。<br/><br/>     韩东目前所在的房间便是【处理室】。<br/><br/>     “国外的监狱？死后重生？我到底是一个什么东西？”<br/><br/>     这些的问题并没有困扰韩东太久。<br/><br/>     长期走在前沿科学的他，接纳新事物的能力极强。<br/><br/>     短时间内意识到自己是一团具备保护膜的独立细胞团体，虽不清楚一团细胞是如何能独立存活与承载意识。<br/><br/>     细胞是生命活动的基本单位，足以证明他还没有死。<br/><br/>     “所谓的死亡穿越发生在了我的身上？而且，还穿越成了一团细胞集合体？真是讽刺啊。”<br/><br/>     韩东一生致力于细胞生物学的研究，在半年前于国际顶级期刊Cell上发表了一篇‘关于通过基因编码手段激活并控制细胞调节的作用’的文章。<br/><br/>     因这篇文章而评上副教授的韩东，在全校教师体检中，检测出肺癌晚期……遭受癌细胞的无情侵蚀，前程尽断。<br/><br/>     本应意识消亡而彻底死去的他，却又以细胞团的生命形式重生。<br/><br/>     …………<br/><br/>     没有太多的犹豫，考虑到细胞团也需要能量的补给才能正常活动，当务之急是按照神秘的系统指示，寻找‘合适’的肉体。<br/><br/>     按照地图上的指示。<br/><br/>     韩东通过极其缓慢的‘爬行’方式，前往最近的一间牢房。<br/><br/>     与蜗牛几乎相同的迁移运动，让他花费了足足一整天的时间。<br/><br/>     配对着意识中的地图，对应着象征着‘自己’的小光点，以最短路径迁移到隔壁牢房，首次与监狱内的囚犯尸体接触。<br/><br/>     “幸好有地图的指示，不然在五感完全丧失的情况下，真的麻烦……”<br/><br/>     接触到尸体的一瞬间。<br/><br/>     韩东的意识层面，立即显出一道完整的人体剖面图，同时还配有详细的文字标注，可在意识层面进行查看。<br/><br/>     坎贝尔.弗兰克（生前为地下黑拳手）<br/><br/>     【头颅】劣等、负重需求：5<br/><br/>     【左臂】普通、负重需求：11<br/><br/>     【右臂】优质、具备「快速出拳」技能、负重需求：23<br/><br/>     【躯干】普通、负重需求：13<br/><br/>     【左脚】普通、负重需求：11<br/><br/>     【右脚】普通、负重需求：14<br/><br/>     一系列的数据信息反馈到韩东的意识层面。<br/><br/>     “囚犯似乎在死前进行过‘特殊处理’，从而让尸体不腐烂，可供我占据与控制。<br/><br/>     之前的提示中说到，如果对于肉体不满意，即可在【处理室】中进行舍弃，重新挑选即可。<br/><br/>     可供选择的肉体还有很多，有必要利用其中一具来了解当前的情况。”<br/><br/>     『请确认你是否要获得「坎贝尔.弗兰克」的全部肉体？所需负重值77。』<br/><br/>     『是！』<br/><br/>     转眼间。<br/><br/>     细胞团由囚犯肉体表面的‘孔’进入体内，短时间内激活全身，生机恢复。<br/><br/>     先是一阵耳鸣声回荡在脑海中。<br/><br/>     紧跟着，冰冷的石制触感从全身各个部位传来……说明神经系统全部接通。<br/><br/>     黑岩与钢筋构成的简易牢房映入眼帘，视觉恢复。<br/><br/>     就在韩东打算对神秘的监狱展开调查与分析，推断自己为何而重生，神秘监狱到底隐藏着什么样的秘密时。<br/><br/>     嗡！整个人突然呆住。<br/><br/>     韩东单手撑着墙面，咬牙切齿而发出怒吼声！<br/><br/>     “哇……这家伙是个智障！”<br/><br/>     完全占据了【坎贝尔.弗兰克】之后，韩东很不好受。<br/><br/>     由于五感的恢复从而得到周围的环境信息，在他进一步，打算通过大脑进行复杂的数据处理时，出了大问题！<br/><br/>     韩东这位意识本体，可是知名大学生命科学院里最年轻的副教授，学霸级的存在。<br/><br/>     但意识归意识，当意识通过感官收集到数据、拟化出相关的处理公式，想要交给大脑进行处理时却出了大问题！<br/><br/>     就好像买了一张败家之眼2080ti的显卡，然而这样的顶级显卡却装在一台CPU仅为老版本I3处理器的主机中。<br/><br/>     问题更大的是，这处理器还进过水！！<br/><br/>     因大量数据的引入，系统近乎崩溃。<br/><br/>     韩东只能将眼睛闭上、嘴里默念大悲咒，尽可能减少外界信息摄取、尽可能将思绪放空！<br/><br/>     否则，这个智障的大脑必将因大量数据的引入而死机，甚至‘烧掉’。</br></br></div>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch = menu_info[0]\n",
    "print(ch.url)\n",
    "source = requests.get(book_url + ch.url)\n",
    "soup = BeautifulSoup(source.text, \"html.parser\")\n",
    "sentences = soup.find(\"div\", attrs={'id':'content'})\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chapter_1.html\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'findAll'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-7f6dc8f79642>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_url\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"html.parser\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"div\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mcontents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'findAll'"
     ]
    }
   ],
   "source": [
    "for ch in menu_info:\n",
    "    t = ch.epub_link\n",
    "    print(\"正在下载：\" + t)\n",
    "    source = requests.get(book_url + ch.url)\n",
    "    soup = BeautifulSoup(source.text, \"html.parser\")\n",
    "    sentences = soup.find(\"div\", attrs={'id':'content'}).findAll(text=True)\n",
    "    contents = []\n",
    "    for s in sentences:\n",
    "        tmp = s.replace('\\xa0', '')\n",
    "        contents.append(f'<p>{tmp}</p>')\n",
    "    with open(f'./{book_title}/OPS/{t}', 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(template % {\n",
    "            'title': ch.chapter_title,\n",
    "            'content': '\\n'.join(contents)\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pack the EPub Book!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we will zip the folder then turn it into a \\*.epub package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all files in the folder\n",
    "file_paths = []\n",
    "for root, directories, files in os.walk(f'./{book_title}'): \n",
    "    for filename in files: \n",
    "        # join the two strings in order to form the full filepath. \n",
    "        filepath = os.path.join(root, filename) \n",
    "        file_paths.append(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations, 我的细胞监狱.epub has been freshly made!\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile(f\"./{book_title}.epub\", \"w\") as z:\n",
    "    for f in file_paths:\n",
    "        z.write(f)\n",
    "        \n",
    "print(f\"Congratulations, {book_title}.epub has been freshly made!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Reference: https://www.jianshu.com/p/75b993cd2f68*\n",
    "## The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
