{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fiction Bot IV\n",
    "### A notebook based automated fiction scraper + EPub generator\n",
    "This notebook is able to scrape and download all chapters from a provided internet novel url (biquge.com.cn), then auto generate a well-formatted ePub ebook, with **Table Of Contents** of course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"xbiquge.so\"\n",
    "book_url = \"https://www.xbiquge.so/book/49842/\"\n",
    "book_dir = \"books/\"\n",
    "project_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Developer\\\\FictionBot-IV'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(book_url)\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "book_title = soup.h1.text\n",
    "author = soup.find(\"meta\", attrs={\"property\":\"og:novel:author\"})['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MenuInfo:\n",
    "    def __init__(self, url, chapter_title):\n",
    "        self.url = url\n",
    "        self.chapter_title = chapter_title\n",
    "        self.id = None\n",
    "        self.epub_link = None\n",
    "    \n",
    "    def get_title(self):\n",
    "        return self.chapter_title\n",
    "    \n",
    "    def get_url(self):\n",
    "        return self.get_url\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.id}: {self.chapter_title} - {self.url} - {self.epub_link}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeXMLText(text):\n",
    "    text = text.replace(\"&\", \"&amp;\")\n",
    "    text = text.replace(\"\\\"\", \"&quot;\")\n",
    "    text = text.replace(\"'\", \"&apos;\")\n",
    "    text = text.replace(\"<\", \"&lt;\")\n",
    "    text = text.replace(\">\", \"&gt;\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch all HTML tags of the menu entries, store in `menu_raw`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_raw = soup.find_all('dd')\n",
    "menu_raw = menu_raw[12:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then parse href and chapter titiles from each HTML tag, store the information in `menu_info`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_info = []\n",
    "for index, data in enumerate(menu_raw, 1):\n",
    "    try:\n",
    "        m = MenuInfo(url = data.a['href'], chapter_title = data.text)\n",
    "        menu_info.append(m)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chapter_1: 第一章 多出的24小时 - 31348841.html - contents/chapter_1.html\n",
      "chapter_2: 第二章 正态分布选书法 - 31348842.html - contents/chapter_2.html\n",
      "chapter_3: 第三章 静止的世界 - 31348843.html - contents/chapter_3.html\n"
     ]
    }
   ],
   "source": [
    "for c, d in enumerate(menu_info, 1):\n",
    "    try:\n",
    "        d.id = f'chapter_{c}'\n",
    "        d.epub_link = f'contents/chapter_{c}.html'\n",
    "    except:\n",
    "        print(d)\n",
    "    \n",
    "for i in range(0, 3):\n",
    "    print(str(menu_info[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Folder Structure for EPub\n",
    "A sample EPUB archive structure may loook like this\n",
    "```\n",
    "mimetype\n",
    "META-INF/\n",
    "   container.xml\n",
    "OEBPS/\n",
    "  content.opf\n",
    "  title.html\n",
    "  contents/\n",
    "      content.html\n",
    "  stylesheet.css\n",
    "  toc.ncx\n",
    "  images/\n",
    "     cover.png\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f\"./{book_dir}{book_title}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot find directory ./books/我的一天有48小时, current dir is: D:\\Developer\\FictionBot-IV\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(output_dir)\n",
    "except:\n",
    "    shutil.rmtree(f\"{output_dir}/\")\n",
    "    os.mkdir(output_dir)\n",
    "    print(f\"Cannot find directory {output_dir}, current dir is: {os.getcwd()}\")\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(f\"{output_dir}/META-INF\")\n",
    "    os.mkdir(f\"{output_dir}/OEBPS\")\n",
    "    os.mkdir(f\"{output_dir}/OEBPS/images\")\n",
    "    os.mkdir(f\"{output_dir}/OEBPS/contents\")\n",
    "except:\n",
    "    print(f\"Cannot find directory {output_dir}, current dir is: {os.getcwd()}\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create `mimetype`\n",
    "\n",
    "Write `application/epub+zip` to the mimetype file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{output_dir}/mimetype\", \"w\") as tmp:\n",
    "    tmp.write(\"application/epub+zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Write below contents to `META-INF/container.xml`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_xml_content ='''<?xml version=\"1.0\"?>\n",
    "<container version=\"1.0\" xmlns=\"urn:oasis:names:tc:opendocument:xmlns:container\">\n",
    "  <rootfiles>\n",
    "    <rootfile full-path=\"OEBPS/content.opf\"\n",
    "     media-type=\"application/oebps-package+xml\" />\n",
    "  </rootfiles>\n",
    "</container>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{output_dir}/META-INF/container.xml\", \"w\", encoding=\"utf-8\") as container:\n",
    "    container.write(container_xml_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create OPF content with meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'81a0dabd-24df-11ed-97a7-10a51d0178df'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "unique_id = str(uuid.uuid1())\n",
    "\n",
    "unique_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "opfcontent = f'''<?xml version='1.0' encoding='utf-8'?>\n",
    "<package xmlns=\"http://www.idpf.org/2007/opf\" xmlns:svg=\"http://www.w3.org/2000/svg\" \n",
    "            unique-identifier=\"{unique_id}\" version=\"2.0\">   \n",
    "    <metadata xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:opf=\"http://www.idpf.org/2007/opf\">\n",
    "%(metadata)s\n",
    "        <meta name=\"cover\" content=\"cover-image\"/>\n",
    "    </metadata>\n",
    "    <manifest>\n",
    "        <item id=\"ncx\" href=\"toc.ncx\" media-type=\"application/x-dtbncx+xml\"/>\n",
    "        <item id=\"cover\" href=\"title.html\" media-type=\"application/xhtml+xml\"/>\n",
    "        <item id=\"cover-image\" href=\"images/cover.jpg\" media-type=\"image/jpeg\"/>\n",
    "%(contents)s\n",
    "    </manifest>\n",
    "    <spine toc=\"ncx\">\n",
    "        <itemref idref=\"cover\" linear=\"no\"/>\n",
    "%(ncx)s\n",
    "    </spine>\n",
    "    <guide>\n",
    "        <reference href=\"title.html\" type=\"cover\" title=\"Cover\"/>\n",
    "    </guide>\n",
    "    \n",
    "</package>\n",
    "'''\n",
    "\n",
    "dc = '\\t\\t<dc:%(tag)s>%(value)s</dc:%(tag)s>'\n",
    "dc_id = '\\t\\t<dc:%(tag)s id=\"%(id)s\" opf:scheme=\"uuid\">%(value)s</dc:%(tag)s>'\n",
    "item = \"\\t\\t<item id='%(id)s' href='%(epub_href)s' media-type='application/xhtml+xml'/>\"\n",
    "itemref = \"\\t\\t<itemref idref='%(id)s'/>\"\n",
    "metadata = '\\n'.join([\n",
    "    dc % {'tag': 'title', 'value': encodeXMLText(book_title)},\n",
    "    dc % {'tag': 'creator', 'value': encodeXMLText(author)},\n",
    "    dc % {'tag': 'language', 'value': \"zh\"},\n",
    "    dc_id % {'tag': 'identifier', 'value': encodeXMLText(unique_id), 'id': 'bookid'},\n",
    "    dc % {'tag': 'description', 'value': \"本文档由 Fiction Bot IV 生成。脚本作者 Jack Zhao\"},\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t<item id='chapter_1' href='contents/chapter_1.html' media-type='application/xhtml+xml'/>\n",
      "\t\t<itemref idref='chapter_1'/>\n"
     ]
    }
   ],
   "source": [
    "manifest = []\n",
    "ncx = []\n",
    "# navpoints = []\n",
    "for m in menu_info:\n",
    "    manifest.append(item % {'id': encodeXMLText(m.id), 'epub_href': encodeXMLText(m.epub_link)})\n",
    "    ncx.append(itemref % {'id': encodeXMLText(m.id)})\n",
    "#     navpoints.append(navpoint % (m.epub_link, m.id, m.chapter_title, m.epub_link))\n",
    "print(manifest[0])\n",
    "print(ncx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{output_dir}/OEBPS/content.opf\", \"w\", encoding=\"utf-8\") as container:\n",
    "    container.write(opfcontent % {\n",
    "        'metadata': metadata,\n",
    "        'contents': '\\n'.join(manifest),\n",
    "        'ncx': '\\n'.join(ncx),\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: NCX content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncxcontent = f'''<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
    "<!DOCTYPE ncx PUBLIC \"-//NISO//DTD ncx 2005-1//EN\" \"http://www.daisy.org/z3986/2005/ncx-2005-1.dtd\">\n",
    "<ncx version=\"2005-1\" xmlns=\"http://www.daisy.org/z3986/2005/ncx/\">\n",
    "    <head>\n",
    "      <meta name=\"dtb:uid\" content=\"{encodeXMLText(unique_id)}\"/>\n",
    "      <meta name=\"dtb:depth\" content=\"1\"/>\n",
    "      <meta name=\"dtb:totalPageCount\" content=\"0\"/>\n",
    "      <meta name=\"dtb:maxPageNumber\" content=\"0\"/>\n",
    "    </head>\n",
    "    <docTitle>\n",
    "        <text>%(title)s</text>\n",
    "    </docTitle>\n",
    "    <docAuthor>\n",
    "        <text>%(creator)s</text>\n",
    "    </docAuthor>\n",
    "    <navMap>\n",
    "%(navpoints)s\n",
    "    </navMap>\n",
    "</ncx>\n",
    "'''\n",
    "navpoint = '''\\t\\t<navPoint id=\"%s\" playOrder=\"%d\">\n",
    "\\t\\t    <navLabel>\n",
    "\\t\\t        <text>%s</text>\n",
    "\\t\\t    </navLabel>\n",
    "\\t\\t    <content src=\"%s\"/>\n",
    "\\t\\t</navPoint>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "navpoints = []\n",
    "navpoints.append(navpoint % (\"cover_page\", 1, \"封面\", \"title.html\"))\n",
    "for i, m in enumerate(menu_info,2):\n",
    "    navpoints.append(navpoint % (encodeXMLText(m.id), i, encodeXMLText(m.chapter_title), encodeXMLText(m.epub_link)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{output_dir}/OEBPS/toc.ncx\", \"w\", encoding=\"utf-8\") as container:\n",
    "    container.write(ncxcontent % {\n",
    "        'title': book_title,\n",
    "        'creator': author,\n",
    "        'navpoints': '\\n'.join(navpoints)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save cover image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_img = soup.find(\"img\")\n",
    "if cover_img:\n",
    "    cover_img = cover_img['src']\n",
    "    img = requests.get(cover_img, stream=True)\n",
    "    if img.status_code == 200:\n",
    "        try:\n",
    "            with open(f\"{output_dir}/OEBPS/images/cover.jpg\", \"wb\") as f:\n",
    "                shutil.copyfileobj(img.raw, f)\n",
    "        except:\n",
    "            print(\"Image failed\")\n",
    "    del img\n",
    "else:\n",
    "    print(\"No cover image was found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write `title.html`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_html=f'''<html xmlns=\"http://www.w3.org/1999/xhtml\">\n",
    "  <head>\n",
    "    <title>{book_title}</title>\n",
    "    <style type=\"text/css\">\n",
    "      h2 \\u007btext-align: center;\\u007d\n",
    "      p \\u007btext-align: center;\\u007d\n",
    "      div \\u007btext-align: center;\\u007d\n",
    "    </style>\n",
    "  </head>\n",
    "  <body>\n",
    "    <div><img id=\"cover-image\" src=\"images/cover.jpg\" alt=\"Cover Page\"/></div>\n",
    "    <h2>{encodeXMLText(book_title)}</h2>\n",
    "    <p>{encodeXMLText(author)}</p>\n",
    "  </body>\n",
    "</html>'''\n",
    "\n",
    "with open(f\"{output_dir}/OEBPS/title.html\", \"w\", encoding=\"utf-8\") as writer:\n",
    "    writer.write(title_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Developer\\\\FictionBot-IV'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''<html xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"zh-CN\">\n",
    "<head>\n",
    "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n",
    "<title>%(title)s</title>\n",
    "</head>\n",
    "<body>\n",
    "<h2>%(title)s</h2>\n",
    "<div>\n",
    "%(content)s\n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1455/1455 [02:12<00:00, 10.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for  ch in tqdm(menu_info):\n",
    "    t = ch.epub_link\n",
    "#     print(\"正在下载：\" + t)\n",
    "    source = requests.get(book_url + ch.url)\n",
    "    soup = BeautifulSoup(source.text, \"html.parser\")\n",
    "    sentences = soup.find(\"div\", attrs={'id':'content'}).findAll(text=True)\n",
    "    contents = []\n",
    "    for s in sentences:\n",
    "        tmp = s.replace('\\xa0', '')\n",
    "        contents.append(f'<p>{encodeXMLText(tmp)}</p>')\n",
    "        \n",
    "    # Remove ads from the first row in contents\n",
    "    if base_url in contents[0]:\n",
    "        contents = contents[1:]\n",
    "    \n",
    "    # Write data into an html file\n",
    "    with open(f'{output_dir}/OEBPS/{t}', 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(template % {\n",
    "            'title': encodeXMLText(ch.chapter_title),\n",
    "            'content': '\\n'.join(contents)\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pack the EPub Book!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we will zip the folder then turn it into a \\*.epub package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Developer\\FictionBot-IV\n",
      "./books/我的一天有48小时\n"
     ]
    }
   ],
   "source": [
    "# Collect all files in the folder\n",
    "print(project_dir)\n",
    "print(output_dir)\n",
    "try:\n",
    "    os.chdir(output_dir)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = []\n",
    "for root, directories, files in os.walk('.'): \n",
    "    for filename in files: \n",
    "        # join the two strings in order to form the full filepath. \n",
    "        filepath = os.path.join(root, filename) \n",
    "        file_paths.append(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations, 我的一天有48小时.epub has been freshly made!\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile(f\"../{book_title}.epub\", \"w\") as z:\n",
    "    for f in file_paths:\n",
    "        z.write(f)\n",
    "        \n",
    "print(f\"Congratulations, {book_title}.epub has been freshly made!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(project_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Reference: https://www.cnblogs.com/linlf03/archive/2011/12/15/2285953.html*\n",
    "## The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
